{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание, вычисление аддитивного аттеншна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "готовый ноутбук слать на o.shlyazhko@corp.mail.ru с заголовком \"Домашнее задание по лекции seq2seq (Ваши Фамилия и Имя)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda0 = torch.cuda.set_device(3)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA')\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.n_words = len(self.index2word)\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "она экономически независима от своих родителей .\tshe is economically independent of her parents .\r\n",
      "она направила наши усилия в нужном направлении .\tshe steered our efforts in the right direction .\r\n",
      "на этом заводе производят телевизоры .\tthey are manufacturing tv sets in this factory .\r\n",
      "она всегда жалуется из за моей маленькой зарплаты .\tshe is always complaining about my small salary .\r\n",
      "они стоят там и едят чипсы .\tthey are standing there and eating potato chips .\r\n",
      "мне не удаётся скомпилировать эту программу .\ti m having some problems compiling this software .\r\n",
      "она улыбнулась в ответ на его нежный взгляд .\tshe smiled in response to his affectionate glance .\r\n",
      "она проводит каждое воскресенье со своей бабушкой .\tshe spends time with her grandmother every sunday .\r\n",
      "каждую субботу после обеда она играет в теннис .\tshe spends every saturday afternoon playing tennis .\r\n",
      "после аварии она перестала бывать на людях .\tshe stopped appearing in public after her accident .\r\n"
     ]
    }
   ],
   "source": [
    "!tail rus_eng_small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLangs():\n",
    "    print(\"Loading dataset...\")\n",
    "    pairs = []\n",
    "    # Read the file and split into lines\n",
    "    with open('rus_eng_small.txt') as f:\n",
    "        for l in tqdm_notebook(f):\n",
    "            pair = [s for s in l.rstrip('\\n').split('\\t')]\n",
    "            pairs.append(pair)\n",
    "\n",
    "    return Lang('rus'), Lang('eng'), pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Read 19288 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 8960\n",
      "eng 3914\n",
      "['я ещё не готов .', 'i m not ready yet .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData():\n",
    "    input_lang, output_lang, pairs = readLangs()\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData()\n",
    "MAX_LENGTH = 10\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, nlayers, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, nlayers)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.nlayers, 1, self.hidden_size, device=device), \\\n",
    "               torch.zeros(self.nlayers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполните метод вычисления аддитивного аттеншна в ячейке ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "готовый ноутбук слать на o.shlyazhko@corp.mail.ru с заголовком \"Домашнее задание по лекции seq2seq (Ваши Фамилия и Имя)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Декодер с механизмом внимания dot-product attention\n",
    "    T1 - шаги входной последовательности\n",
    "    T2 - шаги выходной последовательности\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, nlayers, output_size):\n",
    "        \"\"\"\n",
    "        :param hidden_size - размер вектора состояния рекуррентного слоя\n",
    "        :param nlayers - число рекуррентных слоев\n",
    "        :param output_size - размер словаря выходных текстов\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers = nlayers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        # !!! Define layers needed for additive attention here\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.Wh = nn.Linear(self.hidden_size, self.hidden_size * 2)\n",
    "        self.Ws = nn.Linear(self.hidden_size, self.hidden_size * 2)        \n",
    "        self.softmax = nn.Softmax(dim=1) #dim=1 because shape of input for softmax [B, T1, T2] \n",
    "        self.v = nn.Linear(self.hidden_size * 2, 1)\n",
    "                \n",
    "        self.rnn = nn.LSTM(self.hidden_size, self.hidden_size, nlayers)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        :param x: [T2,B] - входной тензор с предыдущими словами размерностью timestep на batch\n",
    "        :param hidden [1, B, C] - состояние рнн слоя\n",
    "        :param encoder_outputs [T1,B,C] - выходы всех шагов энкодера\n",
    "        :return output: [T2,B,C], hidden - С=hidden_size, возвращается только последний hidden state\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x) # [T2,B,C]\n",
    "        #embedded = self.dropout(embedded)\n",
    "        embedded = embedded.transpose(0, 1) # [B,T2,C]\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1) # [B,T1,C]\n",
    "        \n",
    "        context, attn_weights = self.attention(encoder_outputs, embedded, hidden)\n",
    "        \n",
    "        output = torch.cat((embedded, context), dim=-1)\n",
    "        output = self.attn_combine(output).transpose(0,1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        logits = self.out(output)\n",
    "        output = F.log_softmax(logits, dim=-1)\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def attention(self, encoder_outputs, embedded, hidden):\n",
    "        #c = [B, T2, C] т.к. output = torch.cat((embedded, context), dim=-1)\n",
    "        B = embedded.shape[0]\n",
    "        T1 = encoder_outputs.shape[1]\n",
    "        T2 = embedded.shape[1]\n",
    "        c = torch.zeros(embedded.shape).type(torch.cuda.FloatTensor)\n",
    "        att = torch.zeros((B, T1, T2)).type(torch.cuda.FloatTensor)\n",
    "        for t1 in range(T1):\n",
    "            for t2 in range(T2):\n",
    "                att[:, t1, t2] = self.v(self.tanh(self.Wh(encoder_outputs[:, t1, :]) + self.Ws(embedded[:, t2, :])))\n",
    "        # [B,T2,T1]x[B,T1,C] -> B [T2,T1]x[T1,C] = [B, T2, C]\n",
    "        c = torch.bmm(self.softmax(att).transpose(1, 2), encoder_outputs)\n",
    "        return c, self.softmax(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, \n",
    "          encoder, decoder, \n",
    "          optimizer,  criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    if teacher_forcing_ratio == 1.: # use fast parallel mode\n",
    "        decoder_input = torch.cat([decoder_input, target_tensor[:-1]], dim=0)\n",
    "        decoder_outputs, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_outputs = decoder_outputs.squeeze()\n",
    "        loss += criterion(decoder_outputs, target_tensor.squeeze())\n",
    "        loss_value = loss.item()\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_output = decoder_output.view(decoder_output.size(0), -1)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_tensor[di].unsqueeze(0)  # Teacher forcing\n",
    "            else:\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.detach()\n",
    "        loss_value =  loss.item() / target_length\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_training(encoder, decoder, n_iters, print_every=1000, plot_every=100):\n",
    "    print('Train')\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            dt = time_since(start, iter / n_iters)\n",
    "            print('%s (%d %d%%) %.4f' % (dt, iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden # STATE TRANSFER\n",
    "    \n",
    "        decoded_words = []\n",
    "        decoder_attentions = []\n",
    "        for di in range(max_length):\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions.append(decoder_attention)\n",
    "            decoder_output = decoder_output.view(decoder_output.size(0), -1)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.detach()\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "            word = output_lang.index2word[topi.item()]\n",
    "            decoded_words.append(word)\n",
    "\n",
    "        return decoded_words, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_randomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_iters=10000\n",
    "training_pairs = [tensorsFromPair(random.choice(pairs)) for i in tqdm_notebook(range(n_iters), desc='prepare set')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, 1, hidden_size).to(device)\n",
    "decoder = AttnDecoder(hidden_size, 1, output_lang.n_words).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1.\n",
    "learning_rate=0.001\n",
    "optimizer = optim.Adam(list(encoder.parameters())+list(decoder.parameters()), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Не забудьте запустить тренировку в ячейке ниже, а затем и evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0m 5s (- 9m 46s) (100 1%) 4.6325\n",
      "0m 11s (- 9m 34s) (200 2%) 3.4204\n",
      "0m 17s (- 9m 26s) (300 3%) 3.3667\n",
      "0m 23s (- 9m 33s) (400 4%) 3.2145\n",
      "0m 29s (- 9m 24s) (500 5%) 2.9900\n",
      "0m 35s (- 9m 12s) (600 6%) 2.7489\n",
      "0m 41s (- 9m 13s) (700 7%) 2.8244\n",
      "0m 47s (- 9m 4s) (800 8%) 3.0379\n",
      "0m 53s (- 8m 58s) (900 9%) 2.9766\n",
      "0m 59s (- 8m 56s) (1000 10%) 2.9011\n",
      "1m 5s (- 8m 52s) (1100 11%) 2.8617\n",
      "1m 11s (- 8m 46s) (1200 12%) 2.9413\n",
      "1m 18s (- 8m 42s) (1300 13%) 2.8386\n",
      "1m 23s (- 8m 35s) (1400 14%) 2.6738\n",
      "1m 29s (- 8m 28s) (1500 15%) 2.6852\n",
      "1m 35s (- 8m 22s) (1600 16%) 2.7346\n",
      "1m 41s (- 8m 17s) (1700 17%) 2.6126\n",
      "1m 47s (- 8m 11s) (1800 18%) 2.5916\n",
      "1m 53s (- 8m 4s) (1900 19%) 2.7113\n",
      "1m 59s (- 7m 59s) (2000 20%) 2.4710\n",
      "2m 5s (- 7m 52s) (2100 21%) 2.6020\n",
      "2m 11s (- 7m 46s) (2200 22%) 2.5850\n",
      "2m 17s (- 7m 41s) (2300 23%) 2.4774\n",
      "2m 23s (- 7m 35s) (2400 24%) 2.5217\n",
      "2m 30s (- 7m 30s) (2500 25%) 2.5850\n",
      "2m 36s (- 7m 25s) (2600 26%) 2.4388\n",
      "2m 41s (- 7m 17s) (2700 27%) 2.3166\n",
      "2m 47s (- 7m 11s) (2800 28%) 2.4764\n",
      "2m 53s (- 7m 5s) (2900 28%) 2.5402\n",
      "2m 59s (- 6m 58s) (3000 30%) 2.5030\n",
      "3m 5s (- 6m 53s) (3100 31%) 2.4330\n",
      "3m 11s (- 6m 47s) (3200 32%) 2.6551\n",
      "3m 17s (- 6m 41s) (3300 33%) 2.5110\n",
      "3m 23s (- 6m 35s) (3400 34%) 2.4215\n",
      "3m 29s (- 6m 29s) (3500 35%) 2.4261\n",
      "3m 36s (- 6m 24s) (3600 36%) 2.3959\n",
      "3m 41s (- 6m 17s) (3700 37%) 2.2867\n",
      "3m 47s (- 6m 11s) (3800 38%) 2.3869\n",
      "3m 53s (- 6m 5s) (3900 39%) 2.4450\n",
      "3m 59s (- 5m 59s) (4000 40%) 2.2670\n",
      "4m 5s (- 5m 52s) (4100 41%) 2.3185\n",
      "4m 11s (- 5m 47s) (4200 42%) 2.3671\n",
      "4m 17s (- 5m 40s) (4300 43%) 2.3528\n",
      "4m 22s (- 5m 34s) (4400 44%) 2.2813\n",
      "4m 28s (- 5m 28s) (4500 45%) 2.2342\n",
      "4m 34s (- 5m 21s) (4600 46%) 2.2923\n",
      "4m 39s (- 5m 15s) (4700 47%) 2.3635\n",
      "4m 46s (- 5m 9s) (4800 48%) 2.2920\n",
      "4m 51s (- 5m 3s) (4900 49%) 2.2210\n",
      "4m 57s (- 4m 57s) (5000 50%) 2.1658\n",
      "5m 3s (- 4m 51s) (5100 51%) 2.2696\n",
      "5m 9s (- 4m 45s) (5200 52%) 2.3372\n",
      "5m 14s (- 4m 39s) (5300 53%) 2.2070\n",
      "5m 20s (- 4m 33s) (5400 54%) 2.2653\n",
      "5m 26s (- 4m 27s) (5500 55%) 2.2125\n",
      "5m 33s (- 4m 21s) (5600 56%) 2.3347\n",
      "5m 39s (- 4m 16s) (5700 56%) 2.2278\n",
      "5m 45s (- 4m 10s) (5800 57%) 2.3149\n",
      "5m 51s (- 4m 4s) (5900 59%) 2.3511\n",
      "5m 57s (- 3m 58s) (6000 60%) 2.1908\n",
      "6m 3s (- 3m 52s) (6100 61%) 2.1282\n",
      "6m 9s (- 3m 46s) (6200 62%) 2.2090\n",
      "6m 15s (- 3m 40s) (6300 63%) 2.0695\n",
      "6m 21s (- 3m 34s) (6400 64%) 2.1654\n",
      "6m 27s (- 3m 28s) (6500 65%) 2.2387\n",
      "6m 34s (- 3m 23s) (6600 66%) 2.1495\n",
      "6m 40s (- 3m 17s) (6700 67%) 2.0502\n",
      "6m 45s (- 3m 10s) (6800 68%) 1.9842\n",
      "6m 51s (- 3m 4s) (6900 69%) 1.9647\n",
      "6m 56s (- 2m 58s) (7000 70%) 2.0668\n",
      "7m 2s (- 2m 52s) (7100 71%) 1.9013\n",
      "7m 7s (- 2m 46s) (7200 72%) 2.0160\n",
      "7m 13s (- 2m 40s) (7300 73%) 2.0455\n",
      "7m 19s (- 2m 34s) (7400 74%) 1.9372\n",
      "7m 25s (- 2m 28s) (7500 75%) 2.1633\n",
      "7m 31s (- 2m 22s) (7600 76%) 2.1346\n",
      "7m 37s (- 2m 16s) (7700 77%) 2.0945\n",
      "7m 43s (- 2m 10s) (7800 78%) 2.0851\n",
      "7m 49s (- 2m 4s) (7900 79%) 2.0653\n",
      "7m 55s (- 1m 58s) (8000 80%) 2.0001\n",
      "8m 1s (- 1m 52s) (8100 81%) 2.0740\n",
      "8m 7s (- 1m 47s) (8200 82%) 2.0323\n",
      "8m 13s (- 1m 41s) (8300 83%) 1.9040\n",
      "8m 19s (- 1m 35s) (8400 84%) 1.9337\n",
      "8m 25s (- 1m 29s) (8500 85%) 1.8788\n",
      "8m 31s (- 1m 23s) (8600 86%) 2.0386\n",
      "8m 37s (- 1m 17s) (8700 87%) 1.9387\n",
      "8m 43s (- 1m 11s) (8800 88%) 2.1019\n",
      "8m 48s (- 1m 5s) (8900 89%) 2.0316\n",
      "8m 54s (- 0m 59s) (9000 90%) 1.8884\n",
      "9m 0s (- 0m 53s) (9100 91%) 2.0879\n",
      "9m 6s (- 0m 47s) (9200 92%) 1.8521\n",
      "9m 12s (- 0m 41s) (9300 93%) 1.9825\n",
      "9m 18s (- 0m 35s) (9400 94%) 2.0220\n",
      "9m 24s (- 0m 29s) (9500 95%) 1.9154\n",
      "9m 30s (- 0m 23s) (9600 96%) 1.8923\n",
      "9m 36s (- 0m 17s) (9700 97%) 1.9386\n",
      "9m 42s (- 0m 11s) (9800 98%) 1.9018\n",
      "9m 48s (- 0m 5s) (9900 99%) 1.8850\n",
      "9m 53s (- 0m 0s) (10000 100%) 1.9291\n"
     ]
    }
   ],
   "source": [
    "run_training(encoder, decoder, n_iters, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> я не принимаю ничью сторону .\n",
      "= i m not taking sides .\n",
      "< i m not going to die .\n",
      "\n",
      "> мы готовы играть .\n",
      "= we re ready to play .\n",
      "< we re going to die .\n",
      "\n",
      "> я всё ещё живу в бостоне .\n",
      "= i m still living in boston .\n",
      "< i m still in the same team .\n",
      "\n",
      "> я не страдаю клаустрофобией .\n",
      "= i m not claustrophobic .\n",
      "< i m not going to die .\n",
      "\n",
      "> он молод душой .\n",
      "= he is young at heart .\n",
      "< he is a great team .\n",
      "\n",
      "> вы внесены в список .\n",
      "= you re on the list .\n",
      "< you re going to kill the truth .\n",
      "\n",
      "> меня беспокоит твоя безопасность .\n",
      "= i m worried about your safety .\n",
      "< i m trying to be alive .\n",
      "\n",
      "> она тратит столько же денег, сколько зарабатывает .\n",
      "= she spends as much money as she earns .\n",
      "< she is too young to do this .\n",
      "\n",
      "> я рад, что мы поговорили .\n",
      "= i m glad we talked .\n",
      "< i m glad i can help .\n",
      "\n",
      "> они симпатичные .\n",
      "= they re cute .\n",
      "< they re both .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = я очень осторожна .\n",
      "output = i m very well .\n",
      "input = они всё ещё живут со своими родителями .\n",
      "output = they re still on the same team .\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_yticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence)\n",
    "    attentions = torch.cat(attentions).squeeze().cpu()\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"я очень осторожна .\")\n",
    "evaluateAndShowAttention(\"они всё ещё живут со своими родителями .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {
    "584695473c364ca2bcca2176821e4600": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "6915839eda0c4fa8ba10ceb8e3272c5f": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
