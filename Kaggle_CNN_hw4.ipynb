{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7IBizZ1UDEw"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import random\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mu8nF_Y08vEj"
   },
   "outputs": [],
   "source": [
    "#отключает warnings pytorch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ov-7o7eyJGB"
   },
   "outputs": [],
   "source": [
    "DEVICE_ID = 0\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQkqFyVFyUm0"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100500)\n",
    "\n",
    "def data2image(data):\n",
    "    res = np.transpose(np.reshape(data ,(3, 32,32)), (1,2,0))\n",
    "    return PIL.Image.fromarray(np.uint8(res))\n",
    "\n",
    "def imshow(img):\n",
    "    if isinstance(img, torch.Tensor): img = img.numpy().astype('uint8')\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "def prediction2classes(output_var):\n",
    "    _, predicted = torch.max(output_var.data, 1)\n",
    "    predicted.squeeze_()\n",
    "    classes = predicted.tolist()\n",
    "    return classes\n",
    "\n",
    "def make_solution_pytorch(net, input_tensor, a_batch_size):\n",
    "    res = []\n",
    "    net = net.eval()\n",
    "    cur_pos = 0\n",
    "    while cur_pos <= len(input_tensor):\n",
    "        outputs = net(input_tensor[cur_pos:cur_pos+a_batch_size])\n",
    "        res += prediction2classes(outputs)\n",
    "        cur_pos += a_batch_size\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06AeKEiWUa-h"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, input_path, is_train=True, transform=None):\n",
    "                        \n",
    "        data = np.load(input_path)\n",
    "        if is_train: \n",
    "            self.Y, self.X = np.hsplit(data, [1]) \n",
    "            self.Y = [item[0] for item in self.Y]\n",
    "        else: \n",
    "            self.X = data\n",
    "            self.Y = None\n",
    "            \n",
    "        self.X = self.X.reshape((self.X.shape[0], 3, 32, 32))\n",
    "        self.X = self.X.transpose((0, 2, 3, 1)) #приводим к виду (N, H, W, C)\n",
    "        self.X = [Image.fromarray(img) for img in self.X]\n",
    "                \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.X[idx]\n",
    "\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "\n",
    "        if self.Y is None: return sample\n",
    "        else: return (sample, self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-MYsKTfw2ZW"
   },
   "outputs": [],
   "source": [
    "train_path = 'homework_4.train.npy'\n",
    "test_path  = 'homework_4_no_classes.test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gM30XxszmwA"
   },
   "outputs": [],
   "source": [
    "np_mean = np.mean([item[0].numpy() for item in CifarDataset( train_path, transform=transforms.ToTensor())], axis=(0,2,3))\n",
    "np_std = np.std([item[0].numpy() for item in CifarDataset( train_path, transform=transforms.ToTensor())], axis=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rqv5HTGPz1UL"
   },
   "outputs": [],
   "source": [
    "cifar_transform_norm = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")\n",
    "\n",
    "cifar_test_transform_norm = transforms.Compose([    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "oJmzKcvRz8Pe",
    "outputId": "7bad1396-7e1b-44d4-b0e0-daa44b2df64b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "45000\n"
     ]
    }
   ],
   "source": [
    "dataset_train_norm = CifarDataset( train_path, transform=cifar_transform_norm)\n",
    "dataset_valid_norm = CifarDataset( train_path, transform=cifar_test_transform_norm)\n",
    "\n",
    "num_train = len(dataset_train_norm)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.1 * num_train))\n",
    "print(num_train)\n",
    "\n",
    "np.random.seed(100500)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "print(len(train_idx))\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "dataloader_train_norm = DataLoader(dataset_train_norm, batch_size=128,\n",
    "                        sampler=train_sampler, num_workers=4)\n",
    "# dataloader_train_norm = DataLoader(dataset_train_norm, batch_size=128,\n",
    "#                         shuffle=True, num_workers=4)\n",
    "dataloader_valid_norm = DataLoader(dataset_valid_norm, batch_size=128,\n",
    "                        sampler=valid_sampler, num_workers=4)\n",
    "\n",
    "dataset_test_norm = CifarDataset( test_path, is_train=False, transform=cifar_test_transform_norm)\n",
    "dataloader_test_norm = DataLoader(dataset_test_norm, batch_size=128,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "def train_network(a_net, \n",
    "                  a_device,\n",
    "                  dataloader_train_norm=dataloader_train_norm,\n",
    "                  dataloader_valid_norm=dataloader_valid_norm,\n",
    "                  a_epochs=164,\n",
    "                  a_batch_size=128,\n",
    "                  a_lr=0.1):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_acc = []\n",
    "    valid_acc = []\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    net = a_net.to(a_device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr, weight_decay=0.0005, momentum=0.9, nesterov=True)\n",
    "\n",
    "    prev_epoch_time = start_time\n",
    "    lr = a_lr\n",
    "    for epoch in range(a_epochs):  \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            lr /= 20\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=lr, weight_decay=0.0005, momentum=0.9, nesterov=True) \n",
    "        \n",
    "        net = net.train()        \n",
    "        epoch_accuracy = 0.0\n",
    "        epoch_iters = 0\n",
    "        epoch_loss = 0.0\n",
    "        for item in dataloader_train_norm:\n",
    "            \n",
    "            epoch_iters += 1\n",
    "\n",
    "            inputs = item[0].to(a_device)\n",
    "            labels = item[1].long().to(a_device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_accuracy += accuracy_score(labels.cpu(), prediction2classes(outputs))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_accuracy /= epoch_iters\n",
    "        train_acc.append(epoch_accuracy)\n",
    "        epoch_loss /= epoch_iters\n",
    "        train_loss.append(epoch_loss)\n",
    "        \n",
    "        net = net.eval()\n",
    "        epoch_iters = 0\n",
    "        epoch_valid_accuracy = 0.0\n",
    "        epoch_valid_loss = 0.0\n",
    "        for item_valid in dataloader_valid_norm:\n",
    "            \n",
    "            epoch_iters += 1\n",
    "            \n",
    "            valid_inputs = item_valid[0].to(a_device)\n",
    "            valid_labels = item_valid[1].long().to(a_device)\n",
    "\n",
    "\n",
    "            valid_outputs = net(valid_inputs)\n",
    "            epoch_valid_accuracy += accuracy_score(valid_labels.cpu(), prediction2classes(valid_outputs))\n",
    "            epoch_valid_loss += criterion(valid_outputs, valid_labels).item()\n",
    "            \n",
    "        epoch_valid_accuracy /= epoch_iters\n",
    "        epoch_valid_loss /= epoch_iters\n",
    "        valid_acc.append(epoch_valid_accuracy)\n",
    "        valid_loss.append(epoch_valid_loss)\n",
    "        net = net.train()\n",
    "        \n",
    "        print(\"Epoch \", epoch, '| train:', 'acc =', round(train_acc[-1], 4), 'loss =', round(epoch_loss, 5), \\\n",
    "              '| valid:', 'acc =', round(valid_acc[-1], 4), 'loss =', round(epoch_valid_loss, 5))\n",
    "        cur_epoch_time = time.time()\n",
    "        print('Epoch time : ', cur_epoch_time - prev_epoch_time )\n",
    "        prev_epoch_time = cur_epoch_time\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            torch.save(net, 'resnet.pth')\n",
    "\n",
    "    print('Finished Training')\n",
    "    print(\"Total time : \", (time.time()-start_time))\n",
    "  \n",
    "    return train_acc, train_loss, valid_acc, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHMd3AltGGJ3"
   },
   "outputs": [],
   "source": [
    "DOWNSAMPLE_COEF = 2\n",
    "\n",
    "def conv3x3(a_in_planes, a_out_planes, a_stride=1):\n",
    "    \"\"\"\n",
    "    Основной строительный блок конволюций для ResNet\n",
    "    Включает в себя padding=1 - чтобы размерность сохранялась после его применения\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(a_in_planes, a_out_planes,  stride=a_stride,\n",
    "                     kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "def conv1x1(a_in_planes, a_out_planes, a_stride=1):\n",
    "    \n",
    "    return nn.Conv2d(a_in_planes, a_out_planes,  stride=a_stride,\n",
    "                     kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "def x_downsample(a_in_channels):\n",
    "     return nn.Conv2d(a_in_channels, \n",
    "               a_in_channels*DOWNSAMPLE_COEF,\n",
    "               kernel_size=1,\n",
    "               stride=2,\n",
    "               bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-ecV9yX0G-o"
   },
   "outputs": [],
   "source": [
    "class CifarResidualBlock(nn.Module):\n",
    "    def __init__(self, a_in_channels, make_downsample=False, use_skip_connection=True, use_dropout=False):\n",
    "        super(CifarResidualBlock, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        self.use_dropout = use_dropout\n",
    "        \n",
    "        if make_downsample: coef = DOWNSAMPLE_COEF\n",
    "        else: coef = 1  \n",
    "            \n",
    "        ### TODO - нужно описать используемые блоки\n",
    "        if use_skip_connection and make_downsample:\n",
    "            self.conv0 = x_downsample(a_in_channels)\n",
    "        else:\n",
    "            self.conv0 = None\n",
    "        self.conv1 = conv3x3(a_in_channels, a_in_channels * coef, a_stride=coef)\n",
    "        self.bn1 = nn.BatchNorm2d(a_in_channels * coef)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.conv2 = conv3x3(a_in_channels * coef, a_in_channels * coef)\n",
    "        self.bn2 = nn.BatchNorm2d(a_in_channels * coef)\n",
    "        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        ###TODO - описать forward блок с учетом флагов make_downsample и use_skip_connection\n",
    "        if self.use_skip_connection:\n",
    "            if self.conv0:\n",
    "                x_id = self.conv0(x)\n",
    "            else:\n",
    "                x_id = x.clone()\n",
    "        else:\n",
    "            x_id = 0\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = F.relu(x + x_id)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNxk8R0I0KZp"
   },
   "outputs": [],
   "source": [
    "class CifarResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CifarResNet, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.features = nn.Sequential()\n",
    "        \n",
    "        self.features.add_module('conv1', nn.Conv2d(3, 64, 3, padding=1, bias=False))\n",
    "        \n",
    "        self.features.add_module('res_block10', CifarResidualBlock(64))\n",
    "        self.features.add_module('res_block11', CifarResidualBlock(64))\n",
    "        self.features.add_module('res_block20', CifarResidualBlock(64, make_downsample=True))#, use_skip_connection=False))\n",
    "\n",
    "        self.features.add_module('res_block21', CifarResidualBlock(128))\n",
    "        self.features.add_module('res_block23', CifarResidualBlock(128))\n",
    "        self.features.add_module('res_block30', CifarResidualBlock(128, make_downsample=True))#, use_skip_connection=False))\n",
    "        \n",
    "        self.features.add_module('res_block31', CifarResidualBlock(256))\n",
    "        self.features.add_module('res_block33', CifarResidualBlock(256))\n",
    "        self.features.add_module('res_block40', CifarResidualBlock(256, make_downsample=True))\n",
    "        \n",
    "        self.features.add_module('res_block41', CifarResidualBlock(512))\n",
    "        self.features.add_module('res_block42', CifarResidualBlock(512))\n",
    "        \n",
    "      \n",
    "      \n",
    "#         self.global_avg_pooling = nn.AvgPool2d(kernel_size=2)\n",
    "        self.bn = nn.BatchNorm2d(512, momentum=0.9)\n",
    "        self.fc_classifier = nn.Linear(512 * 2 * 2, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = F.relu(self.bn(x))      \n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = x.view((x.size()[0], -1))\n",
    "        x = self.fc_classifier(x)\n",
    "        return x\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3525
    },
    "colab_type": "code",
    "id": "n11pGGiuxY2V",
    "outputId": "2971a543-127c-4a1b-f6de-4517a32199ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | train: acc = 0.1191 loss = 3.79845 | valid: acc = 0.1895 loss = 3.36282\n",
      "Epoch time :  302.0008249282837\n",
      "Epoch  1 | train: acc = 0.2308 loss = 3.13259 | valid: acc = 0.2648 loss = 2.9528\n",
      "Epoch time :  297.5660800933838\n",
      "Epoch  2 | train: acc = 0.3015 loss = 2.7667 | valid: acc = 0.3262 loss = 2.66949\n",
      "Epoch time :  297.6891736984253\n",
      "Epoch  3 | train: acc = 0.3665 loss = 2.44503 | valid: acc = 0.376 loss = 2.37807\n",
      "Epoch time :  297.63926124572754\n",
      "Epoch  4 | train: acc = 0.4217 loss = 2.17535 | valid: acc = 0.4414 loss = 2.09345\n",
      "Epoch time :  297.4438865184784\n",
      "Epoch  5 | train: acc = 0.4595 loss = 2.0053 | valid: acc = 0.4375 loss = 2.11187\n",
      "Epoch time :  297.616094827652\n",
      "Epoch  6 | train: acc = 0.4854 loss = 1.8887 | valid: acc = 0.4326 loss = 2.17417\n",
      "Epoch time :  297.41627192497253\n",
      "Epoch  7 | train: acc = 0.5089 loss = 1.79532 | valid: acc = 0.4895 loss = 1.91147\n",
      "Epoch time :  297.5415072441101\n",
      "Epoch  8 | train: acc = 0.5268 loss = 1.71053 | valid: acc = 0.4816 loss = 1.9086\n",
      "Epoch time :  297.30266308784485\n",
      "Epoch  9 | train: acc = 0.5415 loss = 1.65048 | valid: acc = 0.5094 loss = 1.82561\n",
      "Epoch time :  297.5205774307251\n",
      "Epoch  10 | train: acc = 0.5505 loss = 1.60528 | valid: acc = 0.5094 loss = 1.86723\n",
      "Epoch time :  297.0876979827881\n",
      "Epoch  11 | train: acc = 0.5636 loss = 1.56364 | valid: acc = 0.5072 loss = 1.83646\n",
      "Epoch time :  297.2796595096588\n",
      "Epoch  12 | train: acc = 0.5733 loss = 1.52394 | valid: acc = 0.509 loss = 1.91349\n",
      "Epoch time :  296.97084379196167\n",
      "Epoch  13 | train: acc = 0.577 loss = 1.49938 | valid: acc = 0.5354 loss = 1.68742\n",
      "Epoch time :  296.9688239097595\n",
      "Epoch  14 | train: acc = 0.5861 loss = 1.46641 | valid: acc = 0.5367 loss = 1.73255\n",
      "Epoch time :  297.1486003398895\n",
      "Epoch  15 | train: acc = 0.592 loss = 1.43741 | valid: acc = 0.5318 loss = 1.70529\n",
      "Epoch time :  297.5591206550598\n",
      "Epoch  16 | train: acc = 0.5943 loss = 1.41851 | valid: acc = 0.5504 loss = 1.67201\n",
      "Epoch time :  297.28588032722473\n",
      "Epoch  17 | train: acc = 0.6 loss = 1.3987 | valid: acc = 0.5389 loss = 1.68725\n",
      "Epoch time :  297.4636073112488\n",
      "Epoch  18 | train: acc = 0.6098 loss = 1.37453 | valid: acc = 0.5623 loss = 1.57753\n",
      "Epoch time :  297.01060938835144\n",
      "Epoch  19 | train: acc = 0.7053 loss = 1.01304 | valid: acc = 0.6592 loss = 1.22231\n",
      "Epoch time :  297.3472089767456\n",
      "Epoch  20 | train: acc = 0.741 loss = 0.87986 | valid: acc = 0.6715 loss = 1.18122\n",
      "Epoch time :  297.64695024490356\n",
      "Epoch  21 | train: acc = 0.7592 loss = 0.81458 | valid: acc = 0.6812 loss = 1.13478\n",
      "Epoch time :  297.1815013885498\n",
      "Epoch  22 | train: acc = 0.7742 loss = 0.76764 | valid: acc = 0.6861 loss = 1.14669\n",
      "Epoch time :  297.23555302619934\n",
      "Epoch  23 | train: acc = 0.7788 loss = 0.73593 | valid: acc = 0.6797 loss = 1.13843\n",
      "Epoch time :  297.1094014644623\n",
      "Epoch  24 | train: acc = 0.7912 loss = 0.69866 | valid: acc = 0.6764 loss = 1.1621\n",
      "Epoch time :  297.5232787132263\n",
      "Epoch  25 | train: acc = 0.7982 loss = 0.67503 | valid: acc = 0.6826 loss = 1.13999\n",
      "Epoch time :  297.2485451698303\n",
      "Epoch  26 | train: acc = 0.8088 loss = 0.63769 | valid: acc = 0.6951 loss = 1.08988\n",
      "Epoch time :  297.2636330127716\n",
      "Epoch  27 | train: acc = 0.8176 loss = 0.6092 | valid: acc = 0.6916 loss = 1.12291\n",
      "Epoch time :  297.11479330062866\n",
      "Epoch  28 | train: acc = 0.8216 loss = 0.59055 | valid: acc = 0.6941 loss = 1.1129\n",
      "Epoch time :  297.2316963672638\n",
      "Epoch  29 | train: acc = 0.8293 loss = 0.56159 | valid: acc = 0.6949 loss = 1.11256\n",
      "Epoch time :  297.11768865585327\n",
      "Epoch  30 | train: acc = 0.8392 loss = 0.53234 | valid: acc = 0.6963 loss = 1.10117\n",
      "Epoch time :  297.44091272354126\n",
      "Epoch  31 | train: acc = 0.8466 loss = 0.50613 | valid: acc = 0.6893 loss = 1.17689\n",
      "Epoch time :  297.3776454925537\n",
      "Epoch  32 | train: acc = 0.8543 loss = 0.48086 | valid: acc = 0.6947 loss = 1.15124\n",
      "Epoch time :  297.7295949459076\n",
      "Epoch  33 | train: acc = 0.8606 loss = 0.45524 | valid: acc = 0.6902 loss = 1.16113\n",
      "Epoch time :  297.1793520450592\n",
      "Epoch  34 | train: acc = 0.8679 loss = 0.43324 | valid: acc = 0.6914 loss = 1.16757\n",
      "Epoch time :  297.41572427749634\n",
      "Epoch  35 | train: acc = 0.8739 loss = 0.41299 | valid: acc = 0.7002 loss = 1.14546\n",
      "Epoch time :  297.0149133205414\n",
      "Epoch  36 | train: acc = 0.882 loss = 0.38642 | valid: acc = 0.6906 loss = 1.22818\n",
      "Epoch time :  297.2687966823578\n",
      "Epoch  37 | train: acc = 0.8876 loss = 0.36652 | valid: acc = 0.6904 loss = 1.19304\n",
      "Epoch time :  296.77653527259827\n",
      "Epoch  38 | train: acc = 0.8936 loss = 0.34592 | valid: acc = 0.6861 loss = 1.22236\n",
      "Epoch time :  297.22707200050354\n",
      "Epoch  39 | train: acc = 0.9148 loss = 0.29274 | valid: acc = 0.7035 loss = 1.15777\n",
      "Epoch time :  299.14844965934753\n",
      "Epoch  40 | train: acc = 0.9205 loss = 0.2726 | valid: acc = 0.698 loss = 1.16093\n",
      "Epoch time :  299.2325527667999\n",
      "Epoch  41 | train: acc = 0.9246 loss = 0.26407 | valid: acc = 0.6992 loss = 1.16841\n",
      "Epoch time :  299.2751784324646\n",
      "Epoch  42 | train: acc = 0.9245 loss = 0.26021 | valid: acc = 0.6904 loss = 1.19941\n",
      "Epoch time :  299.1211094856262\n",
      "Epoch  43 | train: acc = 0.9275 loss = 0.25099 | valid: acc = 0.6988 loss = 1.20529\n",
      "Epoch time :  299.6030201911926\n",
      "Epoch  44 | train: acc = 0.929 loss = 0.24996 | valid: acc = 0.708 loss = 1.16503\n",
      "Epoch time :  299.1280107498169\n",
      "Epoch  45 | train: acc = 0.9322 loss = 0.24397 | valid: acc = 0.6943 loss = 1.22423\n",
      "Epoch time :  299.4883964061737\n",
      "Epoch  46 | train: acc = 0.9328 loss = 0.23859 | valid: acc = 0.6979 loss = 1.20072\n",
      "Epoch time :  299.18057775497437\n",
      "Epoch  47 | train: acc = 0.9307 loss = 0.23863 | valid: acc = 0.7002 loss = 1.19948\n",
      "Epoch time :  299.47853803634644\n",
      "Epoch  48 | train: acc = 0.9339 loss = 0.23212 | valid: acc = 0.7029 loss = 1.19275\n",
      "Epoch time :  299.32615303993225\n",
      "Epoch  49 | train: acc = 0.9346 loss = 0.22978 | valid: acc = 0.6977 loss = 1.20129\n",
      "Epoch time :  299.5551335811615\n",
      "Epoch  50 | train: acc = 0.9365 loss = 0.22717 | valid: acc = 0.6982 loss = 1.18595\n",
      "Epoch time :  299.1307682991028\n",
      "Epoch  51 | train: acc = 0.9358 loss = 0.22483 | valid: acc = 0.6979 loss = 1.21652\n",
      "Epoch time :  299.4282612800598\n",
      "Epoch  52 | train: acc = 0.9387 loss = 0.21809 | valid: acc = 0.6947 loss = 1.22483\n",
      "Epoch time :  299.16166853904724\n",
      "Epoch  53 | train: acc = 0.9383 loss = 0.21881 | valid: acc = 0.6941 loss = 1.23651\n",
      "Epoch time :  299.61636686325073\n",
      "Epoch  54 | train: acc = 0.9398 loss = 0.21367 | valid: acc = 0.7102 loss = 1.18178\n",
      "Epoch time :  299.0411422252655\n",
      "Epoch  55 | train: acc = 0.9398 loss = 0.21291 | valid: acc = 0.7012 loss = 1.20687\n",
      "Epoch time :  299.3952775001526\n",
      "Epoch  56 | train: acc = 0.941 loss = 0.20931 | valid: acc = 0.7018 loss = 1.20271\n",
      "Epoch time :  299.31190037727356\n",
      "Epoch  57 | train: acc = 0.9421 loss = 0.20844 | valid: acc = 0.7027 loss = 1.22066\n",
      "Epoch time :  299.4475543498993\n",
      "Epoch  58 | train: acc = 0.9423 loss = 0.20699 | valid: acc = 0.7025 loss = 1.20385\n",
      "Epoch time :  298.9204740524292\n",
      "Epoch  59 | train: acc = 0.9438 loss = 0.2008 | valid: acc = 0.7041 loss = 1.19482\n",
      "Epoch time :  298.72558403015137\n",
      "Epoch  60 | train: acc = 0.9444 loss = 0.1997 | valid: acc = 0.7012 loss = 1.20743\n",
      "Epoch time :  298.96193623542786\n",
      "Epoch  61 | train: acc = 0.9456 loss = 0.19978 | valid: acc = 0.7012 loss = 1.20359\n",
      "Epoch time :  299.0084755420685\n",
      "Epoch  62 | train: acc = 0.9441 loss = 0.19988 | valid: acc = 0.7057 loss = 1.19882\n",
      "Epoch time :  299.4245250225067\n",
      "Epoch  63 | train: acc = 0.9436 loss = 0.20113 | valid: acc = 0.709 loss = 1.16501\n",
      "Epoch time :  298.84328746795654\n",
      "Epoch  64 | train: acc = 0.944 loss = 0.20017 | valid: acc = 0.7066 loss = 1.17457\n",
      "Epoch time :  299.2309060096741\n",
      "Epoch  65 | train: acc = 0.9451 loss = 0.19883 | valid: acc = 0.7076 loss = 1.19694\n",
      "Epoch time :  298.85679483413696\n",
      "Epoch  66 | train: acc = 0.9446 loss = 0.20017 | valid: acc = 0.7023 loss = 1.19616\n",
      "Epoch time :  299.1706347465515\n",
      "Epoch  67 | train: acc = 0.9452 loss = 0.19949 | valid: acc = 0.7006 loss = 1.21259\n",
      "Epoch time :  299.103191614151\n",
      "Epoch  68 | train: acc = 0.9445 loss = 0.20045 | valid: acc = 0.7057 loss = 1.21363\n",
      "Epoch time :  299.41573095321655\n",
      "Epoch  69 | train: acc = 0.946 loss = 0.19811 | valid: acc = 0.7016 loss = 1.22801\n",
      "Epoch time :  298.81334495544434\n",
      "Epoch  70 | train: acc = 0.9453 loss = 0.19719 | valid: acc = 0.7064 loss = 1.1957\n",
      "Epoch time :  299.1990795135498\n",
      "Epoch  71 | train: acc = 0.9458 loss = 0.19751 | valid: acc = 0.6977 loss = 1.20113\n",
      "Epoch time :  298.8320412635803\n",
      "Epoch  72 | train: acc = 0.9445 loss = 0.19959 | valid: acc = 0.6926 loss = 1.26129\n",
      "Epoch time :  299.22327160835266\n",
      "Epoch  73 | train: acc = 0.9464 loss = 0.19625 | valid: acc = 0.7031 loss = 1.23669\n",
      "Epoch time :  299.04732513427734\n",
      "Epoch  74 | train: acc = 0.9449 loss = 0.19995 | valid: acc = 0.7016 loss = 1.23059\n",
      "Epoch time :  299.4220323562622\n",
      "Epoch  75 | train: acc = 0.9451 loss = 0.19905 | valid: acc = 0.6947 loss = 1.25274\n",
      "Epoch time :  298.8621506690979\n",
      "Epoch  76 | train: acc = 0.9447 loss = 0.19517 | valid: acc = 0.6977 loss = 1.19982\n",
      "Epoch time :  298.7363512516022\n",
      "Epoch  77 | train: acc = 0.9455 loss = 0.19543 | valid: acc = 0.698 loss = 1.21491\n",
      "Epoch time :  298.84265971183777\n",
      "Epoch  78 | train: acc = 0.9446 loss = 0.199 | valid: acc = 0.7025 loss = 1.19855\n",
      "Epoch time :  299.279021024704\n",
      "Epoch  79 | train: acc = 0.9441 loss = 0.19877 | valid: acc = 0.7041 loss = 1.23691\n",
      "Epoch time :  299.3363196849823\n",
      "Epoch  80 | train: acc = 0.9472 loss = 0.19415 | valid: acc = 0.7098 loss = 1.17732\n",
      "Epoch time :  298.67092657089233\n",
      "Epoch  81 | train: acc = 0.9458 loss = 0.19554 | valid: acc = 0.7033 loss = 1.18987\n",
      "Epoch time :  299.0491442680359\n",
      "Epoch  82 | train: acc = 0.945 loss = 0.19564 | valid: acc = 0.7008 loss = 1.23339\n",
      "Epoch time :  298.91279554367065\n",
      "Epoch  83 | train: acc = 0.9468 loss = 0.19577 | valid: acc = 0.6992 loss = 1.24496\n",
      "Epoch time :  299.26369190216064\n",
      "Epoch  84 | train: acc = 0.9439 loss = 0.20145 | valid: acc = 0.7018 loss = 1.21452\n",
      "Epoch time :  298.90844106674194\n",
      "Epoch  85 | train: acc = 0.9462 loss = 0.19426 | valid: acc = 0.6973 loss = 1.22806\n",
      "Epoch time :  299.3368809223175\n",
      "Epoch  86 | train: acc = 0.9455 loss = 0.19825 | valid: acc = 0.7008 loss = 1.24807\n",
      "Epoch time :  299.1225805282593\n",
      "Epoch  87 | train: acc = 0.9462 loss = 0.19528 | valid: acc = 0.7037 loss = 1.21013\n",
      "Epoch time :  299.40642642974854\n",
      "Epoch  88 | train: acc = 0.9449 loss = 0.19901 | valid: acc = 0.7055 loss = 1.20763\n",
      "Epoch time :  299.08888387680054\n",
      "Epoch  89 | train: acc = 0.9452 loss = 0.19598 | valid: acc = 0.7012 loss = 1.21087\n",
      "Epoch time :  299.3456802368164\n",
      "Epoch  90 | train: acc = 0.9454 loss = 0.1982 | valid: acc = 0.7018 loss = 1.21049\n",
      "Epoch time :  299.2774353027344\n",
      "Epoch  91 | train: acc = 0.9458 loss = 0.19581 | valid: acc = 0.6973 loss = 1.22391\n",
      "Epoch time :  299.4218592643738\n",
      "Epoch  92 | train: acc = 0.9453 loss = 0.19743 | valid: acc = 0.7105 loss = 1.17477\n",
      "Epoch time :  299.11825156211853\n",
      "Epoch  93 | train: acc = 0.9443 loss = 0.19733 | valid: acc = 0.7041 loss = 1.1919\n",
      "Epoch time :  299.3441581726074\n",
      "Epoch  94 | train: acc = 0.9463 loss = 0.19669 | valid: acc = 0.7002 loss = 1.18254\n",
      "Epoch time :  299.0247106552124\n",
      "Epoch  95 | train: acc = 0.9457 loss = 0.19665 | valid: acc = 0.702 loss = 1.22708\n",
      "Epoch time :  299.5127215385437\n",
      "Epoch  96 | train: acc = 0.9454 loss = 0.19713 | valid: acc = 0.6994 loss = 1.22742\n",
      "Epoch time :  299.2481060028076\n",
      "Epoch  97 | train: acc = 0.9467 loss = 0.19656 | valid: acc = 0.6986 loss = 1.25855\n",
      "Epoch time :  299.56898164749146\n",
      "Epoch  98 | train: acc = 0.9466 loss = 0.19685 | valid: acc = 0.6986 loss = 1.22236\n",
      "Epoch time :  299.2337188720703\n",
      "Epoch  99 | train: acc = 0.9458 loss = 0.19682 | valid: acc = 0.698 loss = 1.2377\n",
      "Epoch time :  299.1178994178772\n",
      "Finished Training\n",
      "Total time :  29850.39179968834\n"
     ]
    }
   ],
   "source": [
    "resnet = CifarResNet()\n",
    "train_acc, train_loss, valid_acc, valid_loss = train_network(resnet, torch.device(DEVICE), a_epochs=100, a_lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "8spj-zDvHT_v",
    "outputId": "d84ae2bb-5195-4946-d5fe-8602986eff78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f22f7ce0b70>]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNCAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label='train', color='b')\n",
    "plt.plot(valid_loss, label='valid', color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYLWE2Km_WHJ"
   },
   "source": [
    "# Важно переключить сеть в режим eval - иначе dropout будет работать некорректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MzYqg_6_Ya1"
   },
   "outputs": [],
   "source": [
    "def make_solution(a_net, a_device):\n",
    "    res = []\n",
    "    net = a_net.eval()\n",
    "    for item in dataloader_test_norm:\n",
    "        inputs = item.to(a_device)\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        res += prediction2classes(outputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQSw5j8c_bf9"
   },
   "outputs": [],
   "source": [
    "my_solution = make_solution(resnet, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0OlzYS98_dVO"
   },
   "outputs": [],
   "source": [
    "file_name = 'my_solution_resnet1.csv'\n",
    "\n",
    "with open(file_name, 'w') as fout:\n",
    "    print('Id', 'Prediction', sep=',', file=fout)\n",
    "    for i, prediction in enumerate(my_solution):\n",
    "        print(i, prediction, sep=',', file=fout)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kaggle_HW4_ResNet_py3_1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
